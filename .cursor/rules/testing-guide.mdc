---
globs: src/backend/tests/**/*,make/test_*.sh,scripts/test_*.py
description: Testing setup and execution guidelines
---

# Testing Guide

## Test Structure

### Test Directories
- [src/backend/tests/](mdc:src/backend/tests/) - Main test directory
- [src/backend/tests/chain/](mdc:src/backend/tests/chain/) - RAG pipeline tests
- [make/](mdc:make/) - Test execution scripts

### Key Test Files
- [src/backend/tests/chain/test_chunking.py](mdc:src/backend/tests/chain/test_chunking.py) - Document chunking tests
- [src/backend/tests/chain/test_retrieving.py](mdc:src/backend/tests/chain/test_retrieving.py) - Vector search tests
- [src/backend/tests/chain/test_generation.py](mdc:src/backend/tests/chain/test_generation.py) - AI generation tests
- [src/backend/tests/chain/test_e2e_rag.py](mdc:src/backend/tests/chain/test_e2e_rag.py) - End-to-end RAG tests
- [src/backend/tests/test_supabase_connection.py](mdc:src/backend/tests/test_supabase_connection.py) - Database connection tests

## Test Execution Scripts

### Individual Test Scripts
- [make/test_chunking.sh](mdc:make/test_chunking.sh) - Test document chunking
- [make/test_retrieving.sh](mdc:make/test_retrieving.sh) - Test vector retrieval
- [make/test_generation.sh](mdc:make/test_generation.sh) - Test AI generation
- [make/test_storing.sh](mdc:make/test_storing.sh) - Test document storage
- [make/test_e2e_rag.sh](mdc:make/test_e2e_rag.sh) - Test complete RAG pipeline

### Comprehensive Test Scripts
- [make/test_all.sh](mdc:make/test_all.sh) - Run all tests
- [make/test_rag_pipeline.sh](mdc:make/test_rag_pipeline.sh) - Test RAG pipeline components
- [make/test_e2e.sh](mdc:make/test_e2e.sh) - End-to-end testing

### Specialized Tests
- [make/test_supabase.sh](mdc:make/test_supabase.sh) - Supabase-specific tests
- [make/test_api.sh](mdc:make/test_api.sh) - API endpoint tests
- [make/test_frontend.sh](mdc:make/test_frontend.sh) - Frontend tests

## Running Tests

### Prerequisites
```bash
# Install dependencies
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys
```

### Individual Test Execution
```bash
# Test specific component
make test_chunking
make test_retrieving
make test_generation

# Test complete pipeline
make test_e2e_rag
```

### Comprehensive Testing
```bash
# Run all tests
make test_all

# Test RAG pipeline
make test_rag_pipeline
```

### Frontend Testing
```bash
# Test frontend locally
make test_frontend

# Test API endpoints
make test_api
```

## Test Configuration

### Environment Setup
Tests require these environment variables:
- `GEMINI_API_KEY` - Google AI API key
- `SUPABASE_URL` - Supabase project URL
- `SUPABASE_ANON_KEY` - Supabase anonymous key

### Test Data
- [data/processed/test_questions.json](mdc:data/processed/test_questions.json) - Test query dataset
- Processed documents in [data/processed/md/](mdc:data/processed/md/)

## Test Categories

### Unit Tests
- **Chunking**: Document text extraction and chunking
- **Embedding**: Vector generation from text
- **Storage**: Document storage in vector database
- **Retrieval**: Similarity search functionality

### Integration Tests
- **RAG Pipeline**: Complete retrieval-augmented generation
- **API Endpoints**: Frontend-backend communication
- **Database**: Supabase vector operations

### End-to-End Tests
- **Complete Workflow**: Query → Retrieval → Generation → Response
- **Frontend Integration**: UI → API → Backend → Database
- **Performance**: Response times and accuracy

## Test Best Practices

### Test Isolation
- Each test should be independent
- Use fixtures for consistent test data
- Clean up after each test

### Error Handling
- Test both success and failure cases
- Verify error messages and status codes
- Test edge cases and boundary conditions

### Performance Testing
- Monitor response times
- Test with various query lengths
- Verify memory usage

### Data Validation
- Check response format and structure
- Validate content quality and relevance
- Test with different document types

## Debugging Tests

### Common Issues
1. **Environment Variables**: Ensure all required keys are set
2. **Database Connection**: Verify Supabase credentials
3. **API Limits**: Check Google AI API quota
4. **Test Data**: Ensure processed documents exist

### Debug Commands
```bash
# Run with verbose output
pytest -v src/backend/tests/

# Run specific test file
pytest src/backend/tests/chain/test_e2e_rag.py

# Run with coverage
pytest --cov=src/backend src/backend/tests/
```

### Logging
- Use `print()` statements for debugging
- Check Vercel function logs for deployment tests
- Monitor Supabase logs for database issues

## Continuous Integration

### Automated Testing
- Run tests on every commit
- Test both local and Vercel deployments
- Monitor test coverage and performance

### Test Reports
- Generate test reports for CI/CD
- Track test performance over time
- Alert on test failures